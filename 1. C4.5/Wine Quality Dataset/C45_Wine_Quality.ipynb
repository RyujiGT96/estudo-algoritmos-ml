{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvore de decisão C4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Será analisado uma base de dados para classificação da qualidade de vinhos. Base de dados pode ser obtida no repositório [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/wine+quality#:~:text=UCI%20Machine%20Learning%20Repository%3A%20Wine%20Quality%20Data%20Set&text=Abstract%3A%20Two%20datasets%20are%20included,%2C%20%5BWeb%20Link%5D).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines = pd.read_csv('wine_quality_dataset.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        0  \n",
       "1         9.5        0  \n",
       "2        10.1        0  \n",
       "3         9.9        0  \n",
       "4         9.9        0  \n",
       "...       ...      ...  \n",
       "4893     11.2        0  \n",
       "4894      9.6        0  \n",
       "4895      9.4        0  \n",
       "4896     12.8        1  \n",
       "4897     11.8        0  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armazenamento dos dados (.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class csvdata():\n",
    "    def __init__(self, classifier):\n",
    "        self.rows = []\n",
    "        self.attributes = []\n",
    "        self.attribute_types = []\n",
    "        self.classifier = classifier\n",
    "        self.class_col_index = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nó da árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decisionTreeNode():\n",
    "    def __init__(self, is_leaf_node, classification, attribute_split_index, attribute_split_value, parent, left_child, right_child, height):\n",
    "        self.is_leaf_node = True\n",
    "        self.classification = None\n",
    "        self.attribute_split = None\n",
    "        self.attribute_split_index = None\n",
    "        self.attribute_split_value = None\n",
    "        self.parent = parent\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        self.height = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento dos dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dataset):\n",
    "    # Conversão dos atributos numéricos em float. 'True' = Numérico e 'False' = Discreto\n",
    "    for example in dataset.rows:\n",
    "        for x in range(len(dataset.rows[0])):\n",
    "            if dataset.attributes[x] == 'True':\n",
    "                example[x] = float(example[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construção da árvore de decisão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_decision_tree(dataset, parent_node, classifier):\n",
    "    # Primeiro criar um nó da árvore\n",
    "    node = decisionTreeNode(True, None, None, None, parent_node, None, None, 0)\n",
    "    # Cálculo da altura da árvore\n",
    "    if (parent_node == None):\n",
    "        node.height = 0\n",
    "    else:\n",
    "        node.height = node.parent.height + 1\n",
    "    # Checar se os dados do nó são puros\n",
    "    ones = count_positives(dataset.rows, dataset.attributes, classifier) #count_positives() irá contar o número de exemplos (rows) com classificação '1'\n",
    "    if (len(dataset.rows) == ones):\n",
    "        node.classification = 1\n",
    "        node.is_leaf_node = True\n",
    "        return node\n",
    "    elif (ones == 0):\n",
    "        node.classification = 0\n",
    "        node.is_leaf_node = True\n",
    "        return node\n",
    "    else:\n",
    "        node.is_leaf_node = False\n",
    "\n",
    "    # Definir o melhor atributo para o split\n",
    "    splitting_attribute = None\n",
    "    # O ganho de informação fornecido pelo melhor atributo\n",
    "    maximum_info_gain = 0\n",
    "    # Limite condicional\n",
    "    split_val = None\n",
    "    # O mínimo valor de ganho de informação permitido\n",
    "    minimum_info_gain = 0.01\n",
    "    # Cálculo da entropia do dataset\n",
    "    entropy = calculate_entropy(dataset, classifier)\n",
    "    for attr_index in range(len(dataset.rows[0])):\n",
    "        if (dataset.attributes[attr_index] != classifier):\n",
    "            local_max_gain = 0\n",
    "            local_split_val = None\n",
    "            attr_value_list = [example[attr_index] for example in dataset.rows] #Dados que serão splitados\n",
    "            attr_value_list = list(set(attr_value_list)) #Remove valores duplicados de atributos\n",
    "            # Caso o atributo for numérico, definir as condições limite para o split\n",
    "            if (len(attr_value_list) > 100):\n",
    "                attr_value_list = sorted(attr_value_list)\n",
    "                total = len(attr_value_list)\n",
    "                ten_percentile = int(total/10)\n",
    "                new_list = []\n",
    "                for x in range(1, 10):\n",
    "                    new_list.append(attr_value_list[x*ten_percentile])\n",
    "                attr_value_list = new_list\n",
    "            # Definição do melhor valor de val\n",
    "            for val in attr_value_list:\n",
    "                # Calcular o valor de ganho utilizando este valor de limite\n",
    "                # Se for maior que local_split_val, salvar este valor na mesma variável\n",
    "                current_gain = calculate_information_gain(attr_index, dataset, val, entropy)\n",
    "                if (current_gain > local_max_gain):\n",
    "                    local_max_gain = current_gain\n",
    "                    local_split_val = val\n",
    "            # Definição do melhor atributo\n",
    "            if (local_max_gain > maximum_info_gain):\n",
    "                maximum_info_gain = local_max_gain\n",
    "                split_val = local_split_val\n",
    "                splitting_attribute = attr_index\n",
    "\n",
    "    # Classificação do nó para casos quase puros\n",
    "    if (maximum_info_gain <= minimum_info_gain or node.height > 20):\n",
    "        node.is_leaf_node = True\n",
    "        node.classification = classify_leaf(dataset, classifier)\n",
    "        return node\n",
    "    \n",
    "    # Informações do nó (leaf) formado\n",
    "    node.attribute_split_index = splitting_attribute\n",
    "    node.attribute_split = dataset.attributes[splitting_attribute]\n",
    "    node.attribute_split_value = split_val\n",
    "\n",
    "    # Construção dos ramos após o split\n",
    "    left_dataset = csvdata(classifier)\n",
    "    right_dataset = csvdata(classifier)\n",
    "    left_dataset.attributes = dataset.attributes\n",
    "    right_dataset.attributes = dataset.attributes\n",
    "    left_dataset.attribute_types = dataset.attribute_types\n",
    "    right_dataset.attribute_types = dataset.attribute_types\n",
    "\n",
    "    # Alocação dos dados para cada ramo criado\n",
    "    for row in dataset.rows:\n",
    "        if (splitting_attribute is not None and row[splitting_attribute] >= split_val):\n",
    "            left_dataset.rows.append(row)\n",
    "        elif (splitting_attribute is not None and row[splitting_attribute] < split_val):\n",
    "            right_dataset.rows.append(row)\n",
    "\n",
    "    # Recursion\n",
    "    node.left_child = compute_decision_tree(left_dataset, node, classifier)\n",
    "    node.right_child = compute_decision_tree(right_dataset, node, classifier)\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação do nó (folha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_leaf(dataset, classifier):\n",
    "    ones = count_positives(dataset.rows, dataset.attributes, classifier)\n",
    "    total = len(dataset.rows)\n",
    "    zeroes = total - ones\n",
    "    if (ones >= zeroes):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para classificação dos dados após treinamento da árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification(example, node, class_col_index):\n",
    "    if (node.is_leaf_node == True):\n",
    "        return node.classification\n",
    "    else:\n",
    "        if (example[node.attribute_split_index] >= node.attribute_split_value):\n",
    "            return get_classification(example, node.left_child, class_col_index)\n",
    "        else:\n",
    "            return get_classification(example, node.right_child, class_col_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de entropia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(dataset, classifier):\n",
    "    # Contagem de rows com classificação '1'\n",
    "    ones = count_positives(dataset.rows, dataset.attributes, classifier)\n",
    "    # Cálculo do número de rows\n",
    "    total_rows = len(dataset.rows)\n",
    "    # A entropia é calculada pela fórmula somatória de -p*log2(p), onde p é a probabilidade de certa classificação\n",
    "    entropy = 0\n",
    "    # Probabilidade p de classificação '1' no dataset total\n",
    "    p = ones/total_rows\n",
    "    if (p != 0):\n",
    "        entropy += p*math.log(p, 2)\n",
    "    # Probabilidade p de classificação '0' no dataset total\n",
    "    p = (total_rows - ones)/total_rows\n",
    "    if (p != 0):\n",
    "        entropy += p*math.log(p, 2)\n",
    "    entropy = -entropy\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de ganho de informação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_gain(attr_index, dataset, val, entropy):\n",
    "    classifier = dataset.attributes[attr_index]\n",
    "    attr_entropy = 0\n",
    "    total_rows = len(dataset.rows)\n",
    "    # criando dois possíveis ramos da árvore \n",
    "    gain_upper_dataset = csvdata(classifier)\n",
    "    gain_lower_dataset = csvdata(classifier)\n",
    "    gain_upper_dataset.attributes = dataset.attributes\n",
    "    gain_lower_dataset.attributes = dataset.attributes\n",
    "    gain_upper_dataset.attribute_types = dataset.attribute_types\n",
    "    gain_lower_dataset.attribute_types = dataset.attribute_types\n",
    "    # split de acordo com val\n",
    "    for example in dataset.rows:\n",
    "        if (example[attr_index] >= val):\n",
    "            gain_upper_dataset.rows.append(example)\n",
    "        elif (example[attr_index] < val):\n",
    "            gain_lower_dataset.rows.append(example)\n",
    "        \n",
    "    if (len(gain_upper_dataset.rows) == 0 or len(gain_lower_dataset.rows) == 0):\n",
    "        return -1\n",
    "\n",
    "    # Cálculo da entropia do atributo utilizado\n",
    "    attr_entropy += calculate_entropy(gain_upper_dataset, classifier)*len(gain_upper_dataset.rows)/total_rows\n",
    "    attr_entropy += calculate_entropy(gain_lower_dataset, classifier)*len(gain_lower_dataset.rows)/total_rows\n",
    "\n",
    "    return entropy - attr_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contador de classes positivas (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_positives(instances, attributes, classifier):\n",
    "    count = 0\n",
    "    class_col_index = None\n",
    "    # Achar o índice do classificador\n",
    "    for a in range(len(attributes)):\n",
    "        if attributes[a] == classifier:\n",
    "            class_col_index = a\n",
    "        else:\n",
    "            class_col_index = len(attributes) - 1\n",
    "    # Contagem de '1's (classes positivas)\n",
    "    for i in instances:\n",
    "        if i[class_col_index] == '1':\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação da árvore após treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_row(node, row):\n",
    "    if (node.is_leaf_node == True):\n",
    "        projected = node.classification\n",
    "        actual = int(row[-1])\n",
    "        if (projected == actual):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    value = row[node.attribute_split_index]\n",
    "    if (value >= node.attribute_split_value):\n",
    "        return validate_row(node.left_child, row)\n",
    "    else:\n",
    "        return validate_row(node.right_child, row)\n",
    "    \n",
    "def validate_tree(node, dataset):\n",
    "    total = len(dataset.rows)\n",
    "    correct = 0\n",
    "    for row in dataset.rows:\n",
    "        # Validação de exemplo (row)\n",
    "        correct += validate_row(node, row)\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poda da árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_tree(root, node, validate_set, best_score):\n",
    "    # Se o nó for uma folha\n",
    "    if (node.is_leaf_node == True):\n",
    "        # classification = node.classification\n",
    "        node.parent.is_leaf_node = True\n",
    "        node.parent.classification = node.classification\n",
    "        if (node.height < 20):\n",
    "            new_score = validate_tree(root, validate_set)\n",
    "        else:\n",
    "            new_score = 0\n",
    "        if (new_score >= best_score):\n",
    "            return new_score\n",
    "        else:\n",
    "            node.parent.is_leaf_node = False\n",
    "            node.parent.classification = None\n",
    "            return best_score\n",
    "    # Se o nó não for uma folha\n",
    "    else:\n",
    "        new_score = prune_tree(root, node.left_child, validate_set, best_score)\n",
    "        if (node.is_leaf_node == True):\n",
    "            return new_score\n",
    "        new_score = prune_tree(root, node.right_child, validate_set, new_score)\n",
    "        if (node.is_leaf_node == True):\n",
    "            return new_score\n",
    "        return new_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento e teste da árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_decision_tree():\n",
    "\n",
    "    # Dados a serem utilizados\n",
    "    dataset = csvdata('')\n",
    "    training_set = csvdata('')\n",
    "    test_set = csvdata('')\n",
    "\n",
    "    # Carregar o dados\n",
    "    f = open('wine_quality_dataset.csv')\n",
    "    original_file = f.read()\n",
    "    # Tratar os dados\n",
    "    rowsplit_data = original_file.splitlines()\n",
    "    dataset.rows = [rows.split(',') for rows in rowsplit_data]\n",
    "    dataset.attributes = dataset.rows.pop(0)\n",
    "    # Printar atributos\n",
    "    print(\"Attributes:\")\n",
    "    print(dataset.attributes)\n",
    "\n",
    "    # Definição dos tipos de atributos (Numérico == 'true' e Nominal == 'false')\n",
    "    # Para cada caso deve ser alterado\n",
    "    dataset.attribute_types = ['true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'false']\n",
    "\n",
    "    # Definir a classe\n",
    "    classifier = dataset.attributes[-1]\n",
    "    dataset.classifier = classifier\n",
    "\n",
    "    # Achar o índice da classe\n",
    "    for a in range(len(dataset.attributes)):\n",
    "        if (dataset.attributes[a] == dataset.classifier):\n",
    "            dataset.class_col_index = a\n",
    "        else:\n",
    "            dataset.class_col_index = len(dataset.attributes) - 1\n",
    "    \n",
    "    # Printar qual é a classe\n",
    "    print(f'Classifier is {dataset.attributes[dataset.class_col_index]} (Index: {dataset.class_col_index})')\n",
    "\n",
    "    # Pré-processamento dos dados\n",
    "    preprocessing(dataset)\n",
    "\n",
    "    # Dados para treinamento, teste e validação\n",
    "    training_set = copy.deepcopy(dataset)\n",
    "    training_set.rows = []\n",
    "    test_set = copy.deepcopy(dataset)\n",
    "    test_set.rows = []\n",
    "    validate_set = copy.deepcopy(dataset)\n",
    "    validate_set.rows = []\n",
    "\n",
    "    # Caso realizar poda (prunning), ativar código abaixo\n",
    "    # Criar o dataset para validação para pós poda (post pruning)\n",
    "    # dataset.rows = [x for i, x in enumerate(dataset.rows) if i % 10 != 9]\n",
    "    # validate_set.rows = [x for i, x in enumerate(dataset.rows) if i % 10 == 9]\n",
    "\n",
    "    # Número de runs a serem realizadas\n",
    "    K = 10\n",
    "    # Armazenar a precisão (accuracy) das 10 runs\n",
    "    accuracy = []\n",
    "    start = time.clock()\n",
    "\n",
    "    for k in range(K):\n",
    "        print('Doing fold', k)\n",
    "        # Parece estar criando novos datasets para treino e teste\n",
    "        training_set.rows = [x for i, x in enumerate(dataset.rows) if i % K != k]\n",
    "        test_set.rows = [x for i, x in enumerate(dataset.rows) if i % K == k]\n",
    "        # Printar quantos exemplos para treino e teste são criados\n",
    "        print(\"Number of training records: %d\" % len(training_set.rows))\n",
    "        print(\"Number of test records: %d\" % len(test_set.rows))\n",
    "\n",
    "        # Construção da árvore\n",
    "        root = compute_decision_tree(training_set, None, classifier)\n",
    "\n",
    "        # este da árvore\n",
    "        # Classificar os dados de teste usando a árvore construída\n",
    "        results = []\n",
    "        for instance in test_set.rows:\n",
    "            result = get_classification(instance, root, test_set.class_col_index)\n",
    "            results.append(str(result) == str(instance[-1]))\n",
    "\n",
    "        # Cálculo da precisão (Accuracy)\n",
    "        acc = float(results.count(True))/float(len(results))\n",
    "        print(\"Accuracy: %.4f\" % acc)\n",
    "\n",
    "        # Se desejar, ativar o código de poda abaixo.\n",
    "        # best_score = validate_tree(root, validate_set)\n",
    "        # post_prune_accuracy = 100*prune_tree(root, root, validate_set, best_score)\n",
    "        # print (\"Post-pruning score on validation set: \" + str(post_prune_accuracy) + \"%\")\n",
    "\n",
    "        accuracy.append(acc)\n",
    "        del root\n",
    "    \n",
    "    mean_accuracy = math.fsum(accuracy)/K\n",
    "    print('Final results:')\n",
    "    print(\"Accuracy  %f \" % (mean_accuracy))\n",
    "    print(\"Took %f secs\" % (time.clock() - start))\n",
    "\n",
    "    '''# Cria um arquivo de resultados\n",
    "    f = open(\"result.txt\", \"w\")\n",
    "    f.write(\"accuracy: %.4f\" % mean_accuracy)\n",
    "    f.close()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes:\n",
      "['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
      "Classifier is quality (Index: 11)\n",
      "Doing fold 0\n",
      "Number of training records: 4408\n",
      "Number of test records: 490\n",
      "Accuracy: 0.8490\n",
      "Doing fold 1\n",
      "Number of training records: 4408\n",
      "Number of test records: 490\n",
      "Accuracy: 0.8327\n",
      "Doing fold 2\n",
      "Number of training records: 4408\n",
      "Number of test records: 490\n",
      "Accuracy: 0.8224\n",
      "Doing fold 3\n",
      "Number of training records: 4408\n",
      "Number of test records: 490\n",
      "Accuracy: 0.8265\n",
      "Doing fold 4\n",
      "Number of training records: 4408\n",
      "Number of test records: 490\n",
      "Accuracy: 0.8714\n",
      "Doing fold 5\n",
      "Number of training records: 4408\n",
      "Number of test records: 490\n",
      "Accuracy: 0.8367\n",
      "Doing fold 6\n",
      "Number of training records: 4408\n",
      "Number of test records: 490\n",
      "Accuracy: 0.8122\n",
      "Doing fold 7\n",
      "Number of training records: 4408\n",
      "Number of test records: 490\n",
      "Accuracy: 0.8327\n",
      "Doing fold 8\n",
      "Number of training records: 4409\n",
      "Number of test records: 489\n",
      "Accuracy: 0.8282\n",
      "Doing fold 9\n",
      "Number of training records: 4409\n",
      "Number of test records: 489\n",
      "Accuracy: 0.8405\n",
      "Final results:\n",
      "Accuracy  0.835239 \n",
      "Took 130.553899 secs\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
